# 关于Python部分的说明

​	最开始我是没想到会在爬取部分花费40%的时间的。原项目数据量较小，因此设置爬取间隔5-10秒时并不会被ban。而随着数据量的增大，不可避免的要和网站的反爬机制斗智斗勇。

目前我所了解的反反爬手段有三：

1、控制速度，最原始的方法，但不一定就不好用。是经过测试不同网站对此的容忍度不同，在我爬京东手机详情页的时候发现即便以10秒左右的间隔，爬200-400条后依然会被ban，而爬评论时就不会，因此要测试后合理选择。

2、更换user-agent，可以直接pip install fake_useragent来做到，但是这个一般是配合别的手段来，同一个ip不停的更换ua在网站管理者的角度来说是极容易检测的。

3、更换ip。最原始的方法当然是重新拨号获得新ip，但这显然不适合大批量爬取，于是一般只能去网上买代理ip的服务。我使用的蜻蜓代理，写这篇文章的时候是25一天(短效优质)，测试效果不是很好，但是横向对比价格比较便宜，见仁见智。一般代理池又主要提供两种服务：①隧道代理，即将请求直接发给服务商的代理池，他负责使用随机的ip访问请求并返回给你结果，这种一般便宜，但是限制的频率一般较低，爬取速度会慢。②ip代理，即需要你自己搭建代理池，代理池向服务商请求ip列表，你根据列表代理ip访问请求，我使用的代理池是https://github.com/jhao104/proxy_pool 。这种就完全看提供的ip质量，如果质量不好，比如我测试的蜻蜓代理一多半不能用，爬起来说不定还不如隧道快，但是如果ip质量好就能很快，因此也许你需要多家对比测试。